{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from Libs.libs import llm\n",
    "from langchain_core.tools import tool\n",
    "from Libs.libs import *\n",
    "# from Tools.Schema import DateModel\n",
    "from typing import Literal\n",
    "import pandas as pd\n",
    "\n",
    "from Libs.libs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "collection_name: str = os.getenv(\"RAG_GYM\")\n",
    "\n",
    "vector_store=Milvus(embedding_function=embeddings,connection_args={ \"host\":host, \"port\":port},collection_name=collection_name)\n",
    "@tool\n",
    "def rag_gym(query: str):\n",
    "    \"\"\"Used to answer the queries related to TATA Punch EV and its variants: Medium Range, Long Range.\"\"\"\n",
    "    context = vector_store.similarity_search(query, k=4)\n",
    "\n",
    "    pprint.pprint(context)\n",
    "    template = \"\"\"You are given a context and a human query.\n",
    "    Do not ever answer using your own knowledge base. \n",
    "\n",
    "    Human query is: {query}\n",
    "    Context is :{context}\n",
    "    Analyze the human query and context and answer the question related \n",
    "    Always ignore the place name mentioned in the query for each and every qeury as the place name does not matter .\n",
    "    Your response should be precise, concise and not contain any irrelevant information.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "    chain = RunnableMap({\n",
    "        'query': lambda x: x['query'],\n",
    "        \"context\": lambda x: vector_store.similarity_search(x['query'], k=6),\n",
    "    }) | prompt | llm | string_parser\n",
    "\n",
    "    res = chain.invoke({\n",
    "        \"query\": query,\n",
    "        })\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def availabilityy(desired_date: str, doctor_name: str):\n",
    "    desired_date_split = desired_date.split(\"T\") or desired_date\n",
    "    print(\"desired date is:\", desired_date)\n",
    "    df = pd.read_csv(f\"./data/syntetic_data/availability.csv\")\n",
    "    date = desired_date_split[0]\n",
    "    time = desired_date_split[1] if len(desired_date_split) > 1 else \"\"\n",
    "    print(time)\n",
    "    # query = doctor_name+ \" for \" + date + \" at time: \" +time\n",
    "    query = doctor_name + \" for \" + date + \",\" + time\n",
    "    # print(f\"{df['date_slot'].apply(lambda x: x.split(' '))}\", query)\n",
    "    availability = pd.DataFrame()\n",
    "    if time != \"\":\n",
    "        availability = df[\n",
    "            (df[\"date_slot\"].apply(lambda x: x.split(\" \")[0]) == date)\n",
    "            & (df[\"date_slot\"].apply(lambda x: x.split(\" \")[1]) == time)\n",
    "            & (doctor_name == df[\"doctor_name\"])\n",
    "            & (df[\"is_available\"] == True)\n",
    "        ]\n",
    "        if availability.empty:\n",
    "            availability = df[\n",
    "                (df[\"date_slot\"].apply(lambda x: x.split(\" \")[0]) == date)\n",
    "                & (doctor_name == df[\"doctor_name\"])\n",
    "                & (df[\"is_available\"] == True)\n",
    "            ]\n",
    "        return query, availability\n",
    "    availability = df[\n",
    "        (df[\"date_slot\"].apply(lambda x: x.split(\" \")[0]) == date)\n",
    "        & (doctor_name == df[\"doctor_name\"])\n",
    "        & (df[\"is_available\"] == True)\n",
    "    ]\n",
    "    print(\"---->>>>>>>\", availability, \">>>-----\", query)\n",
    "    return query, availability\n",
    "\n",
    "\n",
    "# def check_availability_by_doctor(self):\n",
    "@tool\n",
    "def check_availability_by_doctor(\n",
    "    desired_date: str,\n",
    "    doctor_name: Literal[\n",
    "        \"kevin anderson\",\n",
    "        \"robert martinez\",\n",
    "        \"susan davis\",\n",
    "        \"daniel miller\",\n",
    "        \"sarah wilson\",\n",
    "        \"michael green\",\n",
    "        \"lisa brown\",\n",
    "        \"jane smith\",\n",
    "        \"emily johnson\",\n",
    "        \"john doe\",\n",
    "    ],\n",
    "):\n",
    "    # desired_date, doctor_name:Literal['kevin anderson','Ajeet','Rajesh','Shiva','Ganesh',]):\n",
    "    \"\"\"\n",
    "    Check the availability of the doctor with the name of the doctor and date of availability provided\n",
    "    \"\"\"\n",
    "    print()\n",
    "    # print(desired_date)\n",
    "    print(\"from check availability by doctor tool\")\n",
    "    query, availability = availabilityy(\n",
    "        desired_date=desired_date, doctor_name=doctor_name\n",
    "    )\n",
    "    print(\"Tool entered with the query\", query)\n",
    "    # print(availability)\n",
    "    template = \"\"\"\n",
    "    You have to answer the user query which is about the availability of a doctor inquired by patient. You are also given a context that contains the doctors available in that day and a time slot. Analyze and return the doctor name, date and available time slot. \n",
    "        Context inside double backticks:`{context}`\n",
    "        Question inside triple backticks:{question}\n",
    "        Response in markdown format without any backticks and in the context phrase just answer what is asked and if the doctor is not available for a particular time slot, recomend the other time slots.\n",
    "\n",
    "        Your response should be very much conversational in such a way that you are a receptionist talking to a patient who is here to schedule an appointment.\n",
    "        \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    # print(\"context>>>>>>>>>>>>>>>>\",database.similarity_search(query,k=5))\n",
    "    chain = (\n",
    "        RunnableMap(\n",
    "            {\"context\": lambda x: availability, \"question\": lambda x: x[\"question\"]}\n",
    "        )\n",
    "        | prompt\n",
    "        | llm\n",
    "        | string_parser\n",
    "    )\n",
    "    result = chain.invoke({\"question\": query})\n",
    "    print(\"------------\")\n",
    "    mdprint(result)\n",
    "    print(\"------------\")\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def availability_by_specialization(desired_date:str, specialization:str):\n",
    "    desired_date_split = desired_date.split(\"T\") or desired_date\n",
    "\n",
    "    date =  desired_date_split[0] \n",
    "    time = desired_date_split[1] if len(desired_date_split) > 1 else \"\" \n",
    "    df = pd.read_csv(f\"./data/syntetic_data/availability.csv\")\n",
    "    rows = df[(df['date_slot'].apply(lambda input: input.split(' ')[0]) == date) & (df['specialization'] == specialization) & (df['is_available'] == True)].reset_index()\n",
    "    available_specialization = rows[['date_slot', 'specialization', 'doctor_name']] \n",
    "      \n",
    "    query = specialization+ \" for \" + date + \",\" +time\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    return query, available_specialization\n",
    "    \n",
    "\n",
    "# def check_availability_by_specialization(self):\n",
    "\n",
    "@tool\n",
    "def check_availability_by_specialization(desired_date:str, specialization:Literal[\"general_dentist\", \"cosmetic_dentist\", \"prosthodontist\", \"pediatric_dentist\",\"emergency_dentist\",\"oral_surgeon\",\"orthodontist\"]):\n",
    "    \"\"\"\n",
    "    Check the availability of the doctor with specialization and date provided.\n",
    "    \"\"\"\n",
    "    # print(self.senderId)\n",
    "    print(\"from check availability by doctor tool\")\n",
    "    # specialization = \"orthodontist\"\n",
    "    # desired_date = \"2024-09-03\"\n",
    "    \n",
    "    query, available_specialization = availability_by_specialization(desired_date=desired_date, specialization=specialization)\n",
    "    print(\"Tool entered with the query\", query)\n",
    "\n",
    "    template = \"\"\"\n",
    "    You have to answer the user query in which patient is searching for a doctor of a particular specialization which is given in the query. You are also given a context that contains the doctors available in that day and a time slot. Analyze and return the doctor name, date and available time slot along with the specialization. \n",
    "        Context inside double backticks:`{context}`\n",
    "        Question inside triple backticks:{question}\n",
    "    Response in markdown format without any backticks and in the context phrase just answer what is asked and if the doctor is not available for a particular time slot, recomend the other time slots.\n",
    "    Your response should be very much conversational in such a way that you are a receptionist talking to a patient who is here to schedule an appointment.\n",
    "\n",
    "        \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    # print(\"context>>>>>>>>>>>>>>>>\",database.similarity_search(query,k=5))\n",
    "    chain = RunnableMap({\n",
    "        \"context\":lambda x: available_specialization,\n",
    "        \"question\": lambda x: x['question']\n",
    "    }) | prompt | llm | string_parser\n",
    "    result = chain.invoke({'question':query})\n",
    "    mdprint(result)\n",
    "    return result\n",
    "    # return check_specialization\n",
    "    \n",
    "        \n",
    "\n",
    "    # @tool\n",
    "    # def book_appointment( doctor_name:str, desired_time:str):\n",
    "    #     \"\"\"\n",
    "    #     Schedule or Book an appointment for a doctor\n",
    "    #     \"\"\"\n",
    "    #     print(\"Booking appointment tool\")\n",
    "    #     # app = patient_name + \" \" + desired_date + \" \"+ doctor_name + \" \" + specialization + \" \" + desired_time\n",
    "    #     print(\"app\")\n",
    "        \n",
    "    #     return \"Booked \"\n",
    "\n",
    "\n",
    "    # @tool\n",
    "    # def reschedule_appointment(patient_name:str,patient_id:str,desired_date:str, doctor_name:str, specialization:str, desired_time:str):\n",
    "    #     \"\"\"\n",
    "    #     To reschedule an appointment which has already been scheduled to a new date\n",
    "    #     \"\"\"\n",
    "    #     pass\n",
    "\n",
    "@tool\n",
    "def book_appointment(desired_date:str, desired_time:str,  doctor_name:str):\n",
    "    \"\"\"\n",
    "    When the user wants to book an appointment for a doctor at a specified time.\n",
    "\n",
    "    \"\"\"\n",
    "    # print(self.senderId)\n",
    "    patient_id = \"Check123Check\"\n",
    "    patient_name = \"Ajeet Acharya\"\n",
    "    print(\"book tool activated\", desired_date, \" \", desired_time)\n",
    "    availability = pd.DataFrame()\n",
    "    specializations = pd.DataFrame()\n",
    "    # if specialization ==\"\":\n",
    "    desired_date_time = f\"{desired_date}T{desired_time}\"\n",
    "    _, availability = availabilityy(desired_date=desired_date_time, doctor_name=doctor_name)\n",
    "    availability_new = availability[[\"date_slot\",\"specialization\",\"doctor_name\"]]\n",
    "    if len(availability) ==1:\n",
    "        date_id_booking = availability.index[0]\n",
    "        date_slot_booking = availability['date_slot'].iloc[0]\n",
    "        time, date = date_slot_booking.split(\" \")[0],  date_slot_booking.split(\" \")[1]\n",
    "        time = desired_time.split(\":\")\n",
    "        final_time = f\"{time[0]}:{time[1]}\"\n",
    "        if final_time == desired_time:\n",
    "            doctor_name_booking = availability['doctor_name'].iloc[0]\n",
    "            specialization_booking = availability['specialization'].iloc[0]\n",
    "            data = pd.DataFrame({\n",
    "                \"patient_id\": [patient_id],\n",
    "                \"doctor_time_id\": [date_id_booking],\n",
    "                \"patient_name\": [patient_name],\n",
    "                \"doctor_name\": [doctor_name_booking],\n",
    "                \"appointment_date\": [desired_date],\n",
    "                \"appointment_time\": [final_time],\n",
    "                \"specialization\": [specialization_booking],\n",
    "            }\n",
    "        )\n",
    "            \n",
    "            message = write_to_excel(data=data, date_id_booking=date_id_booking, patient_id=patient_id)\n",
    "            print(\"Data written to Excel successfully!\")\n",
    "            return message\n",
    "    else: \n",
    "        return f\"The time slot {desired_time} is not available for {doctor_name}. Please select one of the.\\n {availability_new}\"\n",
    "    # return book_appoint\n",
    "\n",
    "def write_to_excel(data, date_id_booking, patient_id):\n",
    "    data.to_excel(\"./Appointment/doctor_appointments.xlsx\")  # 'index=False' prevents writing row numbers\n",
    "    book_appointment_path = r\"data/syntetic_data/availability.csv\"\n",
    "    df = pd.read_csv(book_appointment_path)\n",
    "    column_no = date_id_booking-2\n",
    "    df.loc[column_no, 'is_available'] = False \n",
    "    df.loc[column_no,'patient_to_attend'] = \"Ajeet123\"\n",
    "    df.to_csv(book_appointment_path, index=False)\n",
    "    return \"Booking has been made sucessfully\"\n",
    "\n",
    "\n",
    "\n",
    "# def reschedule(self):\n",
    "@tool\n",
    "def reschedule(\n",
    "        desired_date: str,\n",
    "        doctor_name: str,\n",
    "        desired_time: str,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        To reschedule an appointment which has already been scheduled to a new date\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        # pass\n",
    "        patient_id = \"Check123Check\"\n",
    "        print(\"reschedule tool activated\", desired_date, \" \", desired_time)\n",
    "        print(\"patient_id\", patient_id)\n",
    "        availability = pd.DataFrame()\n",
    "        appointments_df = pd.read_excel(\"./Appointment/doctor_appointments.xlsx\")\n",
    "        appointment_to_reschedule = appointments_df[\n",
    "            (appointments_df[\"patient_id\"] == patient_id)\n",
    "        ]\n",
    "        if appointment_to_reschedule.empty:\n",
    "            return f\"Error: No appointment found for patient {patient_id}.\"\n",
    "        original_date = f\"{appointment_to_reschedule['appointment_date'].iloc[0]} {appointment_to_reschedule['appointment_time'].iloc[0]}\"\n",
    "        print(\"original date\", original_date)\n",
    "        # doctor_name = appointment_to_reschedule[\"doctor_name\"].iloc[0]\n",
    "        # if specialization ==\"\":\n",
    "        desired_date_time = f\"{desired_date}T{desired_time}\"\n",
    "        _, availability = availabilityy(\n",
    "            desired_date=desired_date_time, doctor_name=doctor_name\n",
    "        )\n",
    "        availability_new = availability[[\"date_slot\", \"specialization\", \"doctor_name\"]]\n",
    "        print(\"availability\", availability)\n",
    "        print(\"availability_new--->\", availability_new)\n",
    "        if not availability.empty:\n",
    "            appointments_df.loc[\n",
    "                appointments_df[\"patient_id\"] == patient_id,\n",
    "                [\"appointment_time\", \"appointment_date\"],\n",
    "            ] = [desired_time, desired_date]\n",
    "\n",
    "            # Write the updated appointment back to Excel\n",
    "            appointments_df.to_excel(\"./Appointment/doctor_appointments.xlsx\", index=False)\n",
    "\n",
    "            message = update_availability_csv(\n",
    "                original_date=original_date,\n",
    "                desired_date=desired_date,\n",
    "                desired_time=desired_time,\n",
    "                patient_id=patient_id,\n",
    "            )\n",
    "\n",
    "            return f\"Appointment rescheduled successfully for {desired_date} at {desired_time}.\\n{message}\"\n",
    "        else:\n",
    "            return f\"Error: The time slot {desired_time} is not available for {doctor_name}. Please choose another slot.\"\n",
    "    # return reschedule_appointment\n",
    "\n",
    "def update_availability_csv(\n",
    "    original_date, desired_date, desired_time,patient_id\n",
    "):\n",
    "\n",
    "    availability_csv_path = r\"data/syntetic_data/availability.csv\"\n",
    "    df = pd.read_csv(availability_csv_path)\n",
    "    desired_date_time = f\"{desired_date} {desired_time}\"\n",
    "\n",
    "    df.loc[ df[\"date_slot\"].str.contains(original_date),\n",
    "        [\"is_available\", \"patient_to_attend\"]\n",
    "    ] = [True, \"\"]\n",
    "\n",
    "    # Update the new time slot to be unavailable (False) and assign the patient to attend\n",
    "    df.loc[df[\"date_slot\"].str.contains(desired_date_time),\n",
    "        [\"is_available\", \"patient_to_attend\"],\n",
    "    ] = [False, patient_id]\n",
    "\n",
    "    # Write the updated DataFrame back to the CSV file\n",
    "    df.to_csv(availability_csv_path, index=False)\n",
    "\n",
    "    return \"Doctor's availability updated successfully.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_available = [check_availability_by_specialization, check_availability_by_doctor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "def create_agent(llm, tools, system_message: str):\n",
    "    \"\"\"Create an agent.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "                \" Use the provided tools to progress towards answering the question.\"\n",
    "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "                \" will help where you left off. Execute what you can to make progress.\"\n",
    "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    return prompt | llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervisor agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "members = [\"Appointments\", \"Rag\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Analyze the user query well and then choose members. You do not need to go to all the members for a query When finished,\"\n",
    "    \" respond with FINISH. Only invoke one worker at once.\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[\"Appointments\", \"Rag\", \"FINISH\"]\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "\n",
    "def supervisor_agent_make(state):\n",
    "    supervisor_chain = prompt | llm.with_structured_output(routeResponse)\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tools.tools_init_ import GetCustomTools\n",
    "\n",
    "toolsInstance = GetCustomTools()\n",
    "tools_available = toolsInstance.get_tools()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprebuilt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_react_agent\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# The agent state is the input to each node in the graph\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m Appointments \u001b[38;5;241m=\u001b[39m create_react_agent(\u001b[43mllm\u001b[49m, tools\u001b[38;5;241m=\u001b[39m[check_availability_by_doctor, check_availability_by_specialization,book_appointment, reschedule ], )\n\u001b[1;32m     17\u001b[0m                                 \u001b[38;5;66;03m#   inter=)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Appointments = create_agent(llm=llm,tools=[check_availability_by_doctor, check_availability_by_specialization,book_appointment, reschedule ],     system_message=\"You are an agent who is responsible for checking the availability of doctor based on doctor's name or specialization , booking appointments or rescheduling appointments of patients.\",\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Rag = create_agent(llm=llm,tools=[rag_gym],system_message=\"You are an agent who is responsible for answering questions related to TATA Punch Ev.\",)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m Rag \u001b[38;5;241m=\u001b[39m create_react_agent(llm, tools\u001b[38;5;241m=\u001b[39m[rag_gym])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "# import functools\n",
    "# import operator\n",
    "# from typing import Sequence\n",
    "# from typing_extensions import TypedDict\n",
    "\n",
    "# from langchain_core.messages import BaseMessage\n",
    "\n",
    "# from langgraph.graph import END, StateGraph, START\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "# # The agent state is the input to each node in the graph\n",
    "\n",
    "\n",
    "\n",
    "# Appointments = create_react_agent(llm, tools=[check_availability_by_doctor, check_availability_by_specialization,book_appointment, reschedule ], )\n",
    "#                                 #   inter=)\n",
    "# # Appointments = create_agent(llm=llm,tools=[check_availability_by_doctor, check_availability_by_specialization,book_appointment, reschedule ],     system_message=\"You are an agent who is responsible for checking the availability of doctor based on doctor's name or specialization , booking appointments or rescheduling appointments of patients.\",\n",
    "# # Rag = create_agent(llm=llm,tools=[rag_gym],system_message=\"You are an agent who is responsible for answering questions related to TATA Punch Ev.\",)\n",
    "# Rag = create_react_agent(llm, tools=[rag_gym])\n",
    "# Appointments_node = functools.partial(agent_node, agent=Appointments, name=\"Appointments\")\n",
    "# Rag_node = functools.partial(agent_node, agent=Rag, name=\"Rag\")\n",
    "\n",
    "# # # NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "# # code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
    "# # code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "# class AgentState(TypedDict):\n",
    "#     # The annotation tells the graph that new messages will always\n",
    "#     # be added to the current states\n",
    "#     messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "#     # The 'next' field indicates where to route to next\n",
    "#     next: str\n",
    "\n",
    "# workflow = StateGraph(AgentState)\n",
    "# workflow.add_node(\"Appointments\", Appointments_node)\n",
    "# workflow.add_node(\"Rag\", Rag_node)\n",
    "# workflow.add_node(\"supervisor_agent\", supervisor_agent_make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n",
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n",
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Branch with name `None` already exists for node `supervisor_agent`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m conditional_map \u001b[38;5;241m=\u001b[39m {k: k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m members}\n\u001b[1;32m     12\u001b[0m conditional_map[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFINISH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m END\n\u001b[0;32m---> 13\u001b[0m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_conditional_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msupervisor_agent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditional_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Finally, add entrypoint\u001b[39;00m\n\u001b[1;32m     16\u001b[0m workflow\u001b[38;5;241m.\u001b[39madd_edge(START, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupervisor_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langgraph/graph/graph.py:293\u001b[0m, in \u001b[0;36mGraph.add_conditional_edges\u001b[0;34m(self, source, path, path_map, then)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;66;03m# validate the condition\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranches[source]:\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBranch with name `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` already exists for node \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m     )\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# save it\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranches[source][name] \u001b[38;5;241m=\u001b[39m Branch(path, path_map_, then)\n",
      "\u001b[0;31mValueError\u001b[0m: Branch with name `None` already exists for node `supervisor_agent`"
     ]
    }
   ],
   "source": [
    "# for member in members:\n",
    "#     # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "#     workflow.add_edge(member, \"supervisor_agent\")\n",
    "workflow.add_edge(\"Appointments\", \"supervisor_agent\")\n",
    "workflow.add_edge(\"Rag\", \"supervisor_agent\")\n",
    "\n",
    "\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor_agent\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "# Finally, add entrypoint\n",
    "workflow.add_edge(START, \"supervisor_agent\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Appointments': 'Appointments', 'Rag': 'Rag', 'FINISH': '__end__'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from Agent.agent_take2 import *\n",
    "from Libs.libs import *\n",
    "# from graph import  graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor_agent': {'next': 'Appointments'}}\n",
      "----\n",
      "\n",
      "from check availability by doctor tool\n",
      "desired date is: 2024-09-03\n",
      "\n",
      "---->>>>>>>              date_slot specialization     doctor_name  is_available  \\\n",
      "4262  2024-09-03 08:00   orthodontist  kevin anderson          True   \n",
      "4263  2024-09-03 08:30   orthodontist  kevin anderson          True   \n",
      "4269  2024-09-03 11:30   orthodontist  kevin anderson          True   \n",
      "4270  2024-09-03 12:00   orthodontist  kevin anderson          True   \n",
      "4271  2024-09-03 12:30   orthodontist  kevin anderson          True   \n",
      "4272  2024-09-03 13:00   orthodontist  kevin anderson          True   \n",
      "4274  2024-09-03 14:00   orthodontist  kevin anderson          True   \n",
      "4275  2024-09-03 14:30   orthodontist  kevin anderson          True   \n",
      "4276  2024-09-03 15:00   orthodontist  kevin anderson          True   \n",
      "4277  2024-09-03 15:30   orthodontist  kevin anderson          True   \n",
      "4279  2024-09-03 16:30   orthodontist  kevin anderson          True   \n",
      "\n",
      "     patient_to_attend  \n",
      "4262               NaN  \n",
      "4263               NaN  \n",
      "4269               NaN  \n",
      "4270               NaN  \n",
      "4271               NaN  \n",
      "4272               NaN  \n",
      "4274               NaN  \n",
      "4275               NaN  \n",
      "4276               NaN  \n",
      "4277               NaN  \n",
      "4279               NaN   >>>----- kevin anderson for 2024-09-03,\n",
      "Tool entered with the query kevin anderson for 2024-09-03,\n",
      "------------\n",
      "Hello! I see that you're looking to schedule an appointment with Dr. Kevin Anderson on September 3rd, 2024. I'm happy to inform you that he is available throughout the day with several time slots open. Here are the available times:\n",
      "\n",
      "- 08:00 AM\n",
      "- 08:30 AM\n",
      "- 11:30 AM\n",
      "- 12:00 PM\n",
      "- 12:30 PM\n",
      "- 01:00 PM\n",
      "- 02:00 PM\n",
      "- 02:30 PM\n",
      "- 03:00 PM\n",
      "- 03:30 PM\n",
      "- 04:30 PM\n",
      "\n",
      "Please let me know which time works best for you, and I'll get that scheduled!\n",
      "------------\n",
      "book tool activated 2024-09-03   08:00 AM\n",
      "desired date is: 2024-09-03T08:00 AM\n",
      "08:00 AM\n",
      "{'Appointments': {'messages': [HumanMessage(content='The 8:00 AM time slot is unfortunately not available for Dr. Kevin Anderson. However, here are the other available times on September 3rd, 2024:\\n\\n- 08:30 AM\\n- 11:30 AM\\n- 12:00 PM\\n- 12:30 PM\\n- 01:00 PM\\n- 02:00 PM\\n- 02:30 PM\\n- 03:00 PM\\n- 03:30 PM\\n- 04:30 PM\\n\\nPlease let me know which time works best for you!', additional_kwargs={}, response_metadata={}, name='Appointments')]}}\n",
      "----\n",
      "{'supervisor_agent': {'next': 'Rag'}}\n",
      "----\n",
      "{'Rag': {'messages': [HumanMessage(content='Please let me know which of the following available time slots for Dr. Kevin Anderson on September 3rd, 2024, works best for you:\\n\\n- 08:30 AM\\n- 11:30 AM\\n- 12:00 PM\\n- 12:30 PM\\n- 01:00 PM\\n- 02:00 PM\\n- 02:30 PM\\n- 03:00 PM\\n- 03:30 PM\\n- 04:30 PM', additional_kwargs={}, response_metadata={}, name='Rag')]}}\n",
      "----\n",
      "{'supervisor_agent': {'next': 'Rag'}}\n",
      "----\n",
      "{'Rag': {'messages': [HumanMessage(content='Please let me know which of the following available time slots for Dr. Kevin Anderson on September 3rd, 2024, works best for you:\\n\\n- 08:30 AM\\n- 11:30 AM\\n- 12:00 PM\\n- 12:30 PM\\n- 01:00 PM\\n- 02:00 PM\\n- 02:30 PM\\n- 03:00 PM\\n- 03:30 PM\\n- 04:30 PM', additional_kwargs={}, response_metadata={}, name='Rag')]}}\n",
      "----\n",
      "{'supervisor_agent': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "query = \"Book an appointment with  doctor kevin anderson available on september 3 2024 at 8 aM\"\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=query)\n",
    "        ]\n",
    "    },\n",
    "        {\"recursion_limit\": 100}\n",
    "\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from Libs.libs import *\n",
    "\n",
    "\n",
    "from Tools.availability_by_doctor import *\n",
    "from Tools.availability_by_specialization import *\n",
    "from Tools.booking import book_appointment\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], operator.add]\n",
    "    senderId:str\n",
    "    history:str\n",
    "    \n",
    "    \n",
    "tools_available = [book_appointment,check_availability_by_doctor, check_availability_by_specialization]\n",
    "# tool = [mercedes_tool]\n",
    "tool_node = ToolNode(tools=tools_available)\n",
    "model = llm.bind_tools(tools = tools_available, strict=True)\n",
    "\n",
    "def read_human_feedback(state):\n",
    "    # if state['messages'][-1].tool_calls == []:\n",
    "    #     logger.info(\"AI: \"+ state['messages'][-1].content)\n",
    "    #     user_msg = input(\"Reply: \")\n",
    "    \n",
    "    \n",
    "    # history = {\"history\":[]}\n",
    "    # history = getData(\"abcsdd\")\n",
    "    # if history is None:\n",
    "    #     history = {'history':[]}\n",
    "    # history_new = {\"human_feedback\":f\"{state['messages'][0].content}\", \"ai\":f\"{state['messages'][-1].content}\"}\n",
    "\n",
    "\n",
    "\n",
    "    # history = history_new.append(history['history'])\n",
    "    # history['history'].append(history_new)\n",
    "    # print(history)\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    # history['history'].append(history_new)\n",
    "    \n",
    "    # setData(state['senderId'], history)\n",
    "    \n",
    "    # if len(history['history'])>4:\n",
    "    #     length = len(history['history']) - 4\n",
    "    #     for i in range(length):\n",
    "    #         history[\"history\"].pop(0)\n",
    "    \n",
    "    # a = getData(\"abcsdd\")\n",
    "    # combined_history.append(a)\n",
    "    # {\"history\":combined_history}\n",
    "        \n",
    "    \n",
    "    \n",
    "    # print()\n",
    "    # print(state)\n",
    "    # print(\"history\",history)\n",
    "    # print()\n",
    "    return state\n",
    "    #     pass\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"From call_model the state is:\",state['senderId'])\n",
    "    s = getData(state[\"senderId\"])\n",
    "    state[\"history\"] = s\n",
    "    \n",
    "\n",
    "    # history = {\"human_feedback\":state[\"messages\"][1], \"AI\":\"This is ai response\"}\n",
    "    messages = [SystemMessage(content=f\"You are helpful assistant.\\n.As reference, today is {datetime.now().strftime('%Y-%m-%d %H:%M, %A')}\\nKeep a friendly, professional tone.\\nAvoid verbosity.\\nConsiderations:\\n- Dont assume parameters in call functions that it didnt say.\\n- MUST NOT force users how to write. Let them write in the way they want.\\n- The conversation should be very natural like a secretary talking with a client.\\n- Call only ONE tool at a time.\")] + state['messages']\n",
    "    # messages = [SystemMessage(content=\"You are a helpful assistant. As reference, today is {datetime.now().strftime('%Y-%m-%d %H:%M, %A')}. Always use tools to answer the queries\")]\n",
    "\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"human_feedback\"]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"human_feedback\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def should_continue_with_feedback(state: MessagesState) -> Literal[\"agent\", \"end\", \"human_feedback\"]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    if isinstance(last_message, dict):\n",
    "        if last_message.get(\"type\",\"\") == 'human_feedback':\n",
    "            return \"agent\"\n",
    "    if (isinstance(last_message, HumanMessage)):\n",
    "        return \"agent\"\n",
    "    if (isinstance(last_message, AIMessage)):\n",
    "        return \"end\"\n",
    "    return \"end\"\n",
    "\n",
    "\n",
    "\n",
    "def graph(query:str, senderId:str):\n",
    "    workflow = StateGraph(MessagesState)\n",
    "    workflow.add_node(\"agent\",call_model)\n",
    "    workflow.add_node(\"tools\",tool_node)\n",
    "    workflow.add_node(\"human_feedback\", read_human_feedback)\n",
    "\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\"human_feedback\":\"human_feedback\",\n",
    "        \"tools\":\"tools\"}\n",
    "    )\n",
    "    workflow.add_conditional_edges(\n",
    "        \"human_feedback\",\n",
    "        should_continue_with_feedback,\n",
    "        {\"agent\":\"agent\",\"end\":END}\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(\"tools\",\"agent\" )\n",
    "\n",
    "\n",
    "    workflow.set_entry_point('agent')\n",
    "\n",
    "\n",
    "\n",
    "    graph = workflow.compile()\n",
    "    inputs = {\"messages\":[HumanMessage(content=query)], \"senderId\":senderId}\n",
    "\n",
    "    for response in graph.stream(inputs):\n",
    "        try:\n",
    "            if \"__end__\" not in response:\n",
    "                print(response)\n",
    "                # if 'human_feedback' in response:\n",
    "                token_usage =response['human_feedback']['messages'][-1].response_metadata['token_usage']\n",
    "                final_response =  response['human_feedback']['messages'][-1].content\n",
    "                    \n",
    "                print(\"-----\")\n",
    "                # history = {\"human_feedback\":query, \"ai\":final_response}\n",
    "                return {\"result\": final_response, \"token_usage\":token_usage}\n",
    "        except Exception as e:\n",
    "            print(\"error\", e)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tools.tools_init_ import *\n",
    "from Libs.libs import *\n",
    "\n",
    "from Libs.libs import llm\n",
    "from Libs.libs import llm\n",
    "\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from Redis.utilis import RedisSaver\n",
    "from Agent.supervisor_agent import agent_node, supervisor_agent_make\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from Libs.libs import *\n",
    "from Tools.tools_init_ import GetCustomTools\n",
    "from Tools.availability_by_doctor import check_availability_by_doctor\n",
    "from Tools.availability_by_specialization import check_availability_by_specialization\n",
    "from Tools.booking import book_appointment\n",
    "from Tools.reschedule import reschedule\n",
    "from Tools.ragAgent import rag_tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{'messages': []}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting step 0 with 1 task:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={})]}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={})]\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={})]}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting step 1 with 1 task:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3msupervisor_agent\u001b[0m -> {'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={})]}\n",
      "next='Appointments'   <class 'Agent.supervisor_agent.routeResponse'>   Appointments\n",
      "Inside should continue Appointments\n",
      "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mnext\u001b[0m -> 'Appointments'\n",
      "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
      "\u001b[0m{'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={})],\n",
      " 'next': 'Appointments'}\n",
      "\u001b[36;1m\u001b[1;3m[2:tasks]\u001b[0m \u001b[1mStarting step 2 with 1 task:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mAppointments\u001b[0m -> {'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={})],\n",
      " 'next': 'Appointments'}\n",
      "{'supervisor_agent': {'next': 'Appointments'}}\n",
      "----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `bookingTool` with `{'desired_date': '2024-10-03', 'desired_time': '16:00', 'doctor_name': 'kevin anderson'}`\n",
      "\n",
      "\n",
      "\u001b[0mbook tool activated 2024-10-03   16:00\n",
      "desired date is: 2024-10-03T16:00\n",
      "16:00\n",
      "Data written to Excel successfully!\n",
      "\u001b[36;1m\u001b[1;3m{'messages': 'Booking has been made sucessfully'}\u001b[0m\u001b[32;1m\u001b[1;3mYour appointment with Dr. Kevin Anderson has been successfully booked for October 3, 2024, at 16:00.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "From agent node {'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={})], 'next': 'Appointments', 'output': 'Your appointment with Dr. Kevin Anderson has been successfully booked for October 3, 2024, at 16:00.', 'intermediate_steps': [(ToolAgentAction(tool='bookingTool', tool_input={'desired_date': '2024-10-03', 'desired_time': '16:00', 'doctor_name': 'kevin anderson'}, log=\"\\nInvoking: `bookingTool` with `{'desired_date': '2024-10-03', 'desired_time': '16:00', 'doctor_name': 'kevin anderson'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_y4sq2Gv9BBbMuazN5cP9btTg', 'function': {'arguments': '{\"desired_date\":\"2024-10-03\",\"desired_time\":\"16:00\",\"doctor_name\":\"kevin anderson\"}', 'name': 'bookingTool'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784'}, id='run-37d49ade-ab65-4fa3-9152-64b29e0d067a', tool_calls=[{'name': 'bookingTool', 'args': {'desired_date': '2024-10-03', 'desired_time': '16:00', 'doctor_name': 'kevin anderson'}, 'id': 'call_y4sq2Gv9BBbMuazN5cP9btTg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 498, 'output_tokens': 35, 'total_tokens': 533}, tool_call_chunks=[{'name': 'bookingTool', 'args': '{\"desired_date\":\"2024-10-03\",\"desired_time\":\"16:00\",\"doctor_name\":\"kevin anderson\"}', 'id': 'call_y4sq2Gv9BBbMuazN5cP9btTg', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_y4sq2Gv9BBbMuazN5cP9btTg'), {'messages': 'Booking has been made sucessfully'})]}\n",
      "\u001b[36;1m\u001b[1;3m[2:writes]\u001b[0m \u001b[1mFinished step 2 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments')]\n",
      "\u001b[36;1m\u001b[1;3m[2:checkpoint]\u001b[0m \u001b[1mState at the end of step 2:\n",
      "\u001b[0m{'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}),\n",
      "              HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments')],\n",
      " 'next': 'Appointments'}\n",
      "\u001b[36;1m\u001b[1;3m[3:tasks]\u001b[0m \u001b[1mStarting step 3 with 1 task:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3msupervisor_agent\u001b[0m -> {'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}),\n",
      "              HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments')],\n",
      " 'next': 'Appointments'}\n",
      "{'Appointments': {'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments')]}}\n",
      "----\n",
      "next='Appointments'   <class 'Agent.supervisor_agent.routeResponse'>   Appointments\n",
      "Inside should continue Appointments\n",
      "\u001b[36;1m\u001b[1;3m[3:writes]\u001b[0m \u001b[1mFinished step 3 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mnext\u001b[0m -> 'Appointments'\n",
      "\u001b[36;1m\u001b[1;3m[3:checkpoint]\u001b[0m \u001b[1mState at the end of step 3:\n",
      "\u001b[0m{'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}),\n",
      "              HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments')],\n",
      " 'next': 'Appointments'}\n",
      "\u001b[36;1m\u001b[1;3m[4:tasks]\u001b[0m \u001b[1mStarting step 4 with 1 task:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mAppointments\u001b[0m -> {'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}),\n",
      "              HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments')],\n",
      " 'next': 'Appointments'}\n",
      "{'supervisor_agent': {'next': 'Appointments'}}\n",
      "----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `bookingTool` with `{'desired_date': '2024-10-03', 'desired_time': '16:00', 'doctor_name': 'kevin anderson'}`\n",
      "\n",
      "\n",
      "\u001b[0mbook tool activated 2024-10-03   16:00\n",
      "desired date is: 2024-10-03T16:00\n",
      "16:00\n",
      "Data written to Excel successfully!\n",
      "\u001b[36;1m\u001b[1;3m{'messages': 'Booking has been made sucessfully'}\u001b[0m\u001b[32;1m\u001b[1;3mYour appointment with Dr. Kevin Anderson has been successfully booked for October 3, 2024, at 16:00.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "From agent node {'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}), HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments')], 'next': 'Appointments', 'output': 'Your appointment with Dr. Kevin Anderson has been successfully booked for October 3, 2024, at 16:00.', 'intermediate_steps': [(ToolAgentAction(tool='bookingTool', tool_input={'desired_date': '2024-10-03', 'desired_time': '16:00', 'doctor_name': 'kevin anderson'}, log=\"\\nInvoking: `bookingTool` with `{'desired_date': '2024-10-03', 'desired_time': '16:00', 'doctor_name': 'kevin anderson'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_Y9aizyUtFxONcIQ93QTCiTOl', 'function': {'arguments': '{\"desired_date\":\"2024-10-03\",\"desired_time\":\"16:00\",\"doctor_name\":\"kevin anderson\"}', 'name': 'bookingTool'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784'}, id='run-d67be80b-0b60-4784-9d2b-56266b7c02ed', tool_calls=[{'name': 'bookingTool', 'args': {'desired_date': '2024-10-03', 'desired_time': '16:00', 'doctor_name': 'kevin anderson'}, 'id': 'call_Y9aizyUtFxONcIQ93QTCiTOl', 'type': 'tool_call'}], usage_metadata={'input_tokens': 532, 'output_tokens': 35, 'total_tokens': 567}, tool_call_chunks=[{'name': 'bookingTool', 'args': '{\"desired_date\":\"2024-10-03\",\"desired_time\":\"16:00\",\"doctor_name\":\"kevin anderson\"}', 'id': 'call_Y9aizyUtFxONcIQ93QTCiTOl', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_Y9aizyUtFxONcIQ93QTCiTOl'), {'messages': 'Booking has been made sucessfully'})]}\n",
      "\u001b[36;1m\u001b[1;3m[4:writes]\u001b[0m \u001b[1mFinished step 4 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments')]\n",
      "\u001b[36;1m\u001b[1;3m[4:checkpoint]\u001b[0m \u001b[1mState at the end of step 4:\n",
      "\u001b[0m{'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}),\n",
      "              HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments'),\n",
      "              HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments')],\n",
      " 'next': 'Appointments'}\n",
      "\u001b[36;1m\u001b[1;3m[5:tasks]\u001b[0m \u001b[1mStarting step 5 with 1 task:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3msupervisor_agent\u001b[0m -> {'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}),\n",
      "              HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments'),\n",
      "              HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments')],\n",
      " 'next': 'Appointments'}\n",
      "{'Appointments': {'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments')]}}\n",
      "----\n",
      "next='Appointments'   <class 'Agent.supervisor_agent.routeResponse'>   Appointments\n",
      "Inside should continue Appointments\n",
      "\u001b[36;1m\u001b[1;3m[5:writes]\u001b[0m \u001b[1mFinished step 5 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mnext\u001b[0m -> 'Appointments'\n",
      "\u001b[36;1m\u001b[1;3m[5:checkpoint]\u001b[0m \u001b[1mState at the end of step 5:\n",
      "\u001b[0m{'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}),\n",
      "              HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments'),\n",
      "              HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments')],\n",
      " 'next': 'Appointments'}\n",
      "\u001b[36;1m\u001b[1;3m[6:tasks]\u001b[0m \u001b[1mStarting step 6 with 1 task:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mAppointments\u001b[0m -> {'messages': [HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}),\n",
      "              HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments'),\n",
      "              HumanMessage(content='book an appointment with doctor kevin anderson for october 3 2024 16:00?', additional_kwargs={}, response_metadata={}, name='Appointments')],\n",
      " 'next': 'Appointments'}\n",
      "{'supervisor_agent': {'next': 'Appointments'}}\n",
      "----\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 135\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[1;32m    133\u001b[0m display(Image(graph\u001b[38;5;241m.\u001b[39mget_graph(xray\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdraw_mermaid_png()))\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecursion_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__end__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1290\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   1285\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[1;32m   1286\u001b[0m         interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[1;32m   1287\u001b[0m         interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[1;32m   1288\u001b[0m         manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m   1289\u001b[0m     ):\n\u001b[0;32m-> 1290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1297\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langgraph/pregel/runner.py:56\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m     54\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langgraph/pregel/retry.py:29\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     27\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langgraph/utils/runnable.py:385\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langgraph/utils/runnable.py:167\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 167\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/Agent/supervisor_agent.py:41\u001b[0m, in \u001b[0;36magent_node\u001b[0;34m(state, agent, name)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magent_node\u001b[39m(state, agent, name):\n\u001b[0;32m---> 41\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrom agent node\u001b[39m\u001b[38;5;124m\"\u001b[39m, result)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39mresult[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent, name\u001b[38;5;241m=\u001b[39mname)],\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;66;03m# \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     }\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain/agents/agent.py:1629\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1629\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1637\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1638\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1639\u001b[0m         )\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain/agents/agent.py:1335\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1328\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1332\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1335\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1345\u001b[0m     )\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain/agents/agent.py:1335\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1328\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1332\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1335\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1338\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1345\u001b[0m     )\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain/agents/agent.py:1363\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1363\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain/agents/agent.py:580\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3405\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m   3400\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3401\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   3402\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3403\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3404\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3405\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3392\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   3387\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3388\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   3389\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3390\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   3391\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 3392\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   3393\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   3394\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   3395\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   3396\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3397\u001b[0m     )\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain_core/runnables/base.py:2193\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   2191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2192\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 2193\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mnext\u001b[39m, iterator)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   2194\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   2195\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3355\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3352\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3353\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[0;32m-> 3355\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain_core/runnables/base.py:1409\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1406\u001b[0m final: Input\n\u001b[1;32m   1407\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1409\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The default implementation of transform is to buffer input and\u001b[39;49;00m\n\u001b[1;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# then call stream.\u001b[39;49;00m\n\u001b[1;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# It'll attempt to gather all input into a single chunk using\u001b[39;49;00m\n\u001b[1;32m   1413\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `+` operator.\u001b[39;49;00m\n\u001b[1;32m   1414\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[1;32m   1415\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk,\u001b[39;49;00m\n\u001b[1;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# and we'll iterate until we get to the last chunk.\u001b[39;49;00m\n\u001b[1;32m   1417\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain_core/runnables/base.py:5550\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   5545\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5546\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   5547\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5548\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   5549\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 5550\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   5551\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   5552\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   5553\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   5554\u001b[0m     )\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain_core/runnables/base.py:1427\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1427\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:418\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    412\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(\n\u001b[1;32m    413\u001b[0m         e,\n\u001b[1;32m    414\u001b[0m         response\u001b[38;5;241m=\u001b[39mLLMResult(\n\u001b[1;32m    415\u001b[0m             generations\u001b[38;5;241m=\u001b[39m[[generation]] \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    416\u001b[0m         ),\n\u001b[1;32m    417\u001b[0m     )\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    420\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(LLMResult(generations\u001b[38;5;241m=\u001b[39m[[generation]]))\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:398\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_limiter\u001b[38;5;241m.\u001b[39macquire(blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:639\u001b[0m, in \u001b[0;36mBaseChatOpenAI._stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m     base_generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 639\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m response:\n\u001b[1;32m    641\u001b[0m     is_first_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/openai/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/openai/resources/chat/completions.py:704\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    702\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    703\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/openai/_base_client.py:1270\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1258\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1265\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1267\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1268\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1269\u001b[0m     )\n\u001b[0;32m-> 1270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/openai/_base_client.py:947\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/openai/_base_client.py:983\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 983\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    989\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/httpx/_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/httpx/_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/httpx/_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    989\u001b[0m     hook(request)\n\u001b[0;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/httpx/_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m     )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/httpx/_transports/default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    245\u001b[0m )\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/ssl.py:1263\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1261\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1262\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/ssl.py:1136\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Tools.tools_init_ import *\n",
    "from Libs.libs import *\n",
    "\n",
    "from Libs.libs import llm\n",
    "from Libs.libs import llm\n",
    "\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from Redis.utilis import RedisSaver\n",
    "from Agent.supervisor_agent import agent_node, supervisor_agent_make\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from Libs.libs import *\n",
    "from Tools.tools_init_ import GetCustomTools\n",
    "from Tools.availability_by_doctor import check_availability_by_doctor\n",
    "from Tools.availability_by_specialization import check_availability_by_specialization\n",
    "from Tools.booking import book_appointment\n",
    "from Tools.reschedule import reschedule\n",
    "from Tools.ragAgent import rag_tool, create_custom_agent\n",
    "\n",
    "query = \"book an appointment with doctor kevin anderson for october 3 2024 16:00?\"\n",
    "\n",
    "\n",
    "\n",
    "def read_human_feedback(state):\n",
    "    return state\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "        \n",
    "def should_continue(state: MessagesState) -> Literal[\"Rag\",\"Appointments\", \"human_feedback\"]:\n",
    "    print(\"Inside should continue\", state['next'])\n",
    "    return state['next']\n",
    "    # messages = state['messages']\n",
    "    # print(\"message\",messages)\n",
    "    # last_message = messages[-1]\n",
    "    # print(\"from should continue\",last_message)\n",
    "    # if isinstance(last_message,routeResponse):\n",
    "    #     return f\"{last_message.next}\"\n",
    "    # return last_message\n",
    "\n",
    "def should_continue_with_feedback(state: MessagesState) -> Literal['supervisor_agent', \"end\", \"human_feedback\"]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    if isinstance(last_message, dict):\n",
    "        if last_message.get(\"type\",\"\") == 'human_feedback':\n",
    "            return \"supervisor_agent\"\n",
    "    if (isinstance(last_message, HumanMessage)):\n",
    "        return \"supervisor_agent\"\n",
    "    if (isinstance(last_message, AIMessage)):\n",
    "        return \"end\"\n",
    "    return \"end\"\n",
    "       \n",
    "        \n",
    "toolsInstance = GetCustomTools()\n",
    "tools_available = toolsInstance.get_tools()\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[\"Appointments\", \"Rag\", \"FINISH\"]\n",
    "\n",
    "from Tools.ragAgent import create_custom_agent\n",
    "Appointments_agnet = create_custom_agent(prompt=\"\"\"You are an intelligent agent that answers queries related to the appointment with doctor based on doctor name, specialization, schedule appointment and reschedule appoinments.\"\"\", tools=tools_available, )\n",
    "Appointments_node = functools.partial(agent_node, agent=Appointments_agnet, name=\"Appointments\")\n",
    "\n",
    "Rag_agent = create_custom_agent(prompt=\"\"\"You are an intelligent agent that answers queries related to TATA Punch EV vehicles and its variants.\"\"\", tools=[rag_tool] )\n",
    "\n",
    "Rag_node = functools.partial(agent_node, agent=Rag_agent, name=\"Rag\")\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Appointments\", Appointments_node)\n",
    "workflow.add_node(\"Rag\", Rag_node)\n",
    "workflow.add_node(\"supervisor_agent\", supervisor_agent_make)\n",
    "workflow.add_node(\"human_feedback\", read_human_feedback)\n",
    "\n",
    "# workflow.add_edge(\"Appointments\", \"supervisor_agent\")\n",
    "conditional_map = {'Appointments': 'Appointments', 'Rag': 'Rag', 'FINISH': '__end__'}\n",
    "# workflow.add_conditional_edges(\"supervisor_agent\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "\"supervisor_agent\",\n",
    "should_continue,\n",
    "        {\n",
    "            \"human_feedback\":\"human_feedback\",\n",
    "            \"Rag\":\"Rag\",\n",
    "            \"Appointments\":\"Appointments\"}\n",
    "    )\n",
    "workflow.add_conditional_edges(\n",
    "    \"human_feedback\",\n",
    "    should_continue_with_feedback,\n",
    "    {\"supervisor_agent\":\"supervisor_agent\",\"end\":END}\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"Appointments\",\n",
    "    should_continue_with_feedback,\n",
    "    {\"supervisor_agent\":\"supervisor_agent\"}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"Rag\",\n",
    "    should_continue_with_feedback,\n",
    "    {\n",
    "        \"supervisor_agent\":\"supervisor_agent\",\n",
    "                }\n",
    ")\n",
    "        \n",
    "        \n",
    "        \n",
    "workflow.add_edge(START, \"supervisor_agent\")\n",
    "graph = workflow.compile(debug=True)\n",
    "\n",
    "\n",
    "\n",
    "        # from Agent.agent_take2 import *\n",
    "from Libs.libs import *\n",
    "# from graph import  graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "for s in graph.stream({\"messages\": [HumanMessage(content=query)]},{\"recursion_limit\": 100}):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")\n",
    "    else:\n",
    "        print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for s in graph.stream({\"messages\": [HumanMessage(content=query)]},{\"recursion_limit\": 100}):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")\n",
    "    else:\n",
    "        print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
