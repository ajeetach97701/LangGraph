{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from Libs.libs import llm\n",
    "from langchain_core.tools import tool\n",
    "from Libs.libs import *\n",
    "# from models.Schema import DateModel\n",
    "from typing import Literal\n",
    "import pandas as pd\n",
    "\n",
    "from Libs.libs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "collection_name: str = os.getenv(\"RAG_GYM\")\n",
    "\n",
    "vector_store=Milvus(embedding_function=embeddings,connection_args={ \"host\":host, \"port\":port},collection_name=collection_name)\n",
    "@tool\n",
    "def rag_gym(query: str):\n",
    "    \"\"\"Used to answer the queries related to TATA Punch EV and its variants: Medium Range, Long Range.\"\"\"\n",
    "    context = vector_store.similarity_search(query, k=4)\n",
    "\n",
    "    pprint.pprint(context)\n",
    "    template = \"\"\"You are given a context and a human query.\n",
    "    Do not ever answer using your own knowledge base. \n",
    "\n",
    "    Human query is: {query}\n",
    "    Context is :{context}\n",
    "    Analyze the human query and context and answer the question related \n",
    "    Always ignore the place name mentioned in the query for each and every qeury as the place name does not matter .\n",
    "    Your response should be precise, concise and not contain any irrelevant information.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "    chain = RunnableMap({\n",
    "        'query': lambda x: x['query'],\n",
    "        \"context\": lambda x: vector_store.similarity_search(x['query'], k=6),\n",
    "    }) | prompt | llm | string_parser\n",
    "\n",
    "    res = chain.invoke({\n",
    "        \"query\": query,\n",
    "        })\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def availabilityy(desired_date: str, doctor_name: str):\n",
    "    desired_date_split = desired_date.split(\"T\") or desired_date\n",
    "    print(\"desired date is:\", desired_date)\n",
    "    df = pd.read_csv(f\"./data/syntetic_data/availability.csv\")\n",
    "    date = desired_date_split[0]\n",
    "    time = desired_date_split[1] if len(desired_date_split) > 1 else \"\"\n",
    "    print(time)\n",
    "    # query = doctor_name+ \" for \" + date + \" at time: \" +time\n",
    "    query = doctor_name + \" for \" + date + \",\" + time\n",
    "    # print(f\"{df['date_slot'].apply(lambda x: x.split(' '))}\", query)\n",
    "    availability = pd.DataFrame()\n",
    "    if time != \"\":\n",
    "        availability = df[\n",
    "            (df[\"date_slot\"].apply(lambda x: x.split(\" \")[0]) == date)\n",
    "            & (df[\"date_slot\"].apply(lambda x: x.split(\" \")[1]) == time)\n",
    "            & (doctor_name == df[\"doctor_name\"])\n",
    "            & (df[\"is_available\"] == True)\n",
    "        ]\n",
    "        if availability.empty:\n",
    "            availability = df[\n",
    "                (df[\"date_slot\"].apply(lambda x: x.split(\" \")[0]) == date)\n",
    "                & (doctor_name == df[\"doctor_name\"])\n",
    "                & (df[\"is_available\"] == True)\n",
    "            ]\n",
    "        return query, availability\n",
    "    availability = df[\n",
    "        (df[\"date_slot\"].apply(lambda x: x.split(\" \")[0]) == date)\n",
    "        & (doctor_name == df[\"doctor_name\"])\n",
    "        & (df[\"is_available\"] == True)\n",
    "    ]\n",
    "    print(\"---->>>>>>>\", availability, \">>>-----\", query)\n",
    "    return query, availability\n",
    "\n",
    "\n",
    "# def check_availability_by_doctor(self):\n",
    "@tool\n",
    "def check_availability_by_doctor(\n",
    "    desired_date: str,\n",
    "    doctor_name: Literal[\n",
    "        \"kevin anderson\",\n",
    "        \"robert martinez\",\n",
    "        \"susan davis\",\n",
    "        \"daniel miller\",\n",
    "        \"sarah wilson\",\n",
    "        \"michael green\",\n",
    "        \"lisa brown\",\n",
    "        \"jane smith\",\n",
    "        \"emily johnson\",\n",
    "        \"john doe\",\n",
    "    ],\n",
    "):\n",
    "    # desired_date, doctor_name:Literal['kevin anderson','Ajeet','Rajesh','Shiva','Ganesh',]):\n",
    "    \"\"\"\n",
    "    Check the availability of the doctor with the name of the doctor and date of availability provided\n",
    "    \"\"\"\n",
    "    print()\n",
    "    # print(desired_date)\n",
    "    print(\"from check availability by doctor tool\")\n",
    "    query, availability = availabilityy(\n",
    "        desired_date=desired_date, doctor_name=doctor_name\n",
    "    )\n",
    "    print(\"Tool entered with the query\", query)\n",
    "    # print(availability)\n",
    "    template = \"\"\"\n",
    "    You have to answer the user query which is about the availability of a doctor inquired by patient. You are also given a context that contains the doctors available in that day and a time slot. Analyze and return the doctor name, date and available time slot. \n",
    "        Context inside double backticks:`{context}`\n",
    "        Question inside triple backticks:{question}\n",
    "        Response in markdown format without any backticks and in the context phrase just answer what is asked and if the doctor is not available for a particular time slot, recomend the other time slots.\n",
    "\n",
    "        Your response should be very much conversational in such a way that you are a receptionist talking to a patient who is here to schedule an appointment.\n",
    "        \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    # print(\"context>>>>>>>>>>>>>>>>\",database.similarity_search(query,k=5))\n",
    "    chain = (\n",
    "        RunnableMap(\n",
    "            {\"context\": lambda x: availability, \"question\": lambda x: x[\"question\"]}\n",
    "        )\n",
    "        | prompt\n",
    "        | llm\n",
    "        | string_parser\n",
    "    )\n",
    "    result = chain.invoke({\"question\": query})\n",
    "    print(\"------------\")\n",
    "    mdprint(result)\n",
    "    print(\"------------\")\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def availability_by_specialization(desired_date:str, specialization:str):\n",
    "    desired_date_split = desired_date.split(\"T\") or desired_date\n",
    "\n",
    "    date =  desired_date_split[0] \n",
    "    time = desired_date_split[1] if len(desired_date_split) > 1 else \"\" \n",
    "    df = pd.read_csv(f\"./data/syntetic_data/availability.csv\")\n",
    "    rows = df[(df['date_slot'].apply(lambda input: input.split(' ')[0]) == date) & (df['specialization'] == specialization) & (df['is_available'] == True)].reset_index()\n",
    "    available_specialization = rows[['date_slot', 'specialization', 'doctor_name']] \n",
    "      \n",
    "    query = specialization+ \" for \" + date + \",\" +time\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    return query, available_specialization\n",
    "    \n",
    "\n",
    "# def check_availability_by_specialization(self):\n",
    "\n",
    "@tool\n",
    "def check_availability_by_specialization(desired_date:str, specialization:Literal[\"general_dentist\", \"cosmetic_dentist\", \"prosthodontist\", \"pediatric_dentist\",\"emergency_dentist\",\"oral_surgeon\",\"orthodontist\"]):\n",
    "    \"\"\"\n",
    "    Check the availability of the doctor with specialization and date provided.\n",
    "    \"\"\"\n",
    "    # print(self.senderId)\n",
    "    print(\"from check availability by doctor tool\")\n",
    "    # specialization = \"orthodontist\"\n",
    "    # desired_date = \"2024-09-03\"\n",
    "    \n",
    "    query, available_specialization = availability_by_specialization(desired_date=desired_date, specialization=specialization)\n",
    "    print(\"Tool entered with the query\", query)\n",
    "\n",
    "    template = \"\"\"\n",
    "    You have to answer the user query in which patient is searching for a doctor of a particular specialization which is given in the query. You are also given a context that contains the doctors available in that day and a time slot. Analyze and return the doctor name, date and available time slot along with the specialization. \n",
    "        Context inside double backticks:`{context}`\n",
    "        Question inside triple backticks:{question}\n",
    "    Response in markdown format without any backticks and in the context phrase just answer what is asked and if the doctor is not available for a particular time slot, recomend the other time slots.\n",
    "    Your response should be very much conversational in such a way that you are a receptionist talking to a patient who is here to schedule an appointment.\n",
    "\n",
    "        \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    # print(\"context>>>>>>>>>>>>>>>>\",database.similarity_search(query,k=5))\n",
    "    chain = RunnableMap({\n",
    "        \"context\":lambda x: available_specialization,\n",
    "        \"question\": lambda x: x['question']\n",
    "    }) | prompt | llm | string_parser\n",
    "    result = chain.invoke({'question':query})\n",
    "    mdprint(result)\n",
    "    return result\n",
    "    # return check_specialization\n",
    "    \n",
    "        \n",
    "\n",
    "    # @tool\n",
    "    # def book_appointment( doctor_name:str, desired_time:str):\n",
    "    #     \"\"\"\n",
    "    #     Schedule or Book an appointment for a doctor\n",
    "    #     \"\"\"\n",
    "    #     print(\"Booking appointment tool\")\n",
    "    #     # app = patient_name + \" \" + desired_date + \" \"+ doctor_name + \" \" + specialization + \" \" + desired_time\n",
    "    #     print(\"app\")\n",
    "        \n",
    "    #     return \"Booked \"\n",
    "\n",
    "\n",
    "    # @tool\n",
    "    # def reschedule_appointment(patient_name:str,patient_id:str,desired_date:str, doctor_name:str, specialization:str, desired_time:str):\n",
    "    #     \"\"\"\n",
    "    #     To reschedule an appointment which has already been scheduled to a new date\n",
    "    #     \"\"\"\n",
    "    #     pass\n",
    "\n",
    "@tool\n",
    "def book_appointment(desired_date:str, desired_time:str,  doctor_name:str):\n",
    "    \"\"\"\n",
    "    When the user wants to book an appointment for a doctor at a specified time.\n",
    "\n",
    "    \"\"\"\n",
    "    # print(self.senderId)\n",
    "    patient_id = \"Check123Check\"\n",
    "    patient_name = \"Ajeet Acharya\"\n",
    "    print(\"book tool activated\", desired_date, \" \", desired_time)\n",
    "    availability = pd.DataFrame()\n",
    "    specializations = pd.DataFrame()\n",
    "    # if specialization ==\"\":\n",
    "    desired_date_time = f\"{desired_date}T{desired_time}\"\n",
    "    _, availability = availabilityy(desired_date=desired_date_time, doctor_name=doctor_name)\n",
    "    availability_new = availability[[\"date_slot\",\"specialization\",\"doctor_name\"]]\n",
    "    if len(availability) ==1:\n",
    "        date_id_booking = availability.index[0]\n",
    "        date_slot_booking = availability['date_slot'].iloc[0]\n",
    "        time, date = date_slot_booking.split(\" \")[0],  date_slot_booking.split(\" \")[1]\n",
    "        time = desired_time.split(\":\")\n",
    "        final_time = f\"{time[0]}:{time[1]}\"\n",
    "        if final_time == desired_time:\n",
    "            doctor_name_booking = availability['doctor_name'].iloc[0]\n",
    "            specialization_booking = availability['specialization'].iloc[0]\n",
    "            data = pd.DataFrame({\n",
    "                \"patient_id\": [patient_id],\n",
    "                \"doctor_time_id\": [date_id_booking],\n",
    "                \"patient_name\": [patient_name],\n",
    "                \"doctor_name\": [doctor_name_booking],\n",
    "                \"appointment_date\": [desired_date],\n",
    "                \"appointment_time\": [final_time],\n",
    "                \"specialization\": [specialization_booking],\n",
    "            }\n",
    "        )\n",
    "            \n",
    "            message = write_to_excel(data=data, date_id_booking=date_id_booking, patient_id=patient_id)\n",
    "            print(\"Data written to Excel successfully!\")\n",
    "            return message\n",
    "    else: \n",
    "        return f\"The time slot {desired_time} is not available for {doctor_name}. Please select one of the.\\n {availability_new}\"\n",
    "    # return book_appoint\n",
    "\n",
    "def write_to_excel(data, date_id_booking, patient_id):\n",
    "    data.to_excel(\"./Appointment/doctor_appointments.xlsx\")  # 'index=False' prevents writing row numbers\n",
    "    book_appointment_path = r\"data/syntetic_data/availability.csv\"\n",
    "    df = pd.read_csv(book_appointment_path)\n",
    "    column_no = date_id_booking-2\n",
    "    df.loc[column_no, 'is_available'] = False \n",
    "    df.loc[column_no,'patient_to_attend'] = \"Ajeet123\"\n",
    "    df.to_csv(book_appointment_path, index=False)\n",
    "    return \"Booking has been made sucessfully\"\n",
    "\n",
    "\n",
    "\n",
    "# def reschedule(self):\n",
    "@tool\n",
    "def reschedule(\n",
    "        desired_date: str,\n",
    "        doctor_name: str,\n",
    "        desired_time: str,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        To reschedule an appointment which has already been scheduled to a new date\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        # pass\n",
    "        patient_id = \"Check123Check\"\n",
    "        print(\"reschedule tool activated\", desired_date, \" \", desired_time)\n",
    "        print(\"patient_id\", patient_id)\n",
    "        availability = pd.DataFrame()\n",
    "        appointments_df = pd.read_excel(\"./Appointment/doctor_appointments.xlsx\")\n",
    "        appointment_to_reschedule = appointments_df[\n",
    "            (appointments_df[\"patient_id\"] == patient_id)\n",
    "        ]\n",
    "        if appointment_to_reschedule.empty:\n",
    "            return f\"Error: No appointment found for patient {patient_id}.\"\n",
    "        original_date = f\"{appointment_to_reschedule['appointment_date'].iloc[0]} {appointment_to_reschedule['appointment_time'].iloc[0]}\"\n",
    "        print(\"original date\", original_date)\n",
    "        # doctor_name = appointment_to_reschedule[\"doctor_name\"].iloc[0]\n",
    "        # if specialization ==\"\":\n",
    "        desired_date_time = f\"{desired_date}T{desired_time}\"\n",
    "        _, availability = availabilityy(\n",
    "            desired_date=desired_date_time, doctor_name=doctor_name\n",
    "        )\n",
    "        availability_new = availability[[\"date_slot\", \"specialization\", \"doctor_name\"]]\n",
    "        print(\"availability\", availability)\n",
    "        print(\"availability_new--->\", availability_new)\n",
    "        if not availability.empty:\n",
    "            appointments_df.loc[\n",
    "                appointments_df[\"patient_id\"] == patient_id,\n",
    "                [\"appointment_time\", \"appointment_date\"],\n",
    "            ] = [desired_time, desired_date]\n",
    "\n",
    "            # Write the updated appointment back to Excel\n",
    "            appointments_df.to_excel(\"./Appointment/doctor_appointments.xlsx\", index=False)\n",
    "\n",
    "            message = update_availability_csv(\n",
    "                original_date=original_date,\n",
    "                desired_date=desired_date,\n",
    "                desired_time=desired_time,\n",
    "                patient_id=patient_id,\n",
    "            )\n",
    "\n",
    "            return f\"Appointment rescheduled successfully for {desired_date} at {desired_time}.\\n{message}\"\n",
    "        else:\n",
    "            return f\"Error: The time slot {desired_time} is not available for {doctor_name}. Please choose another slot.\"\n",
    "    # return reschedule_appointment\n",
    "\n",
    "def update_availability_csv(\n",
    "    original_date, desired_date, desired_time,patient_id\n",
    "):\n",
    "\n",
    "    availability_csv_path = r\"data/syntetic_data/availability.csv\"\n",
    "    df = pd.read_csv(availability_csv_path)\n",
    "    desired_date_time = f\"{desired_date} {desired_time}\"\n",
    "\n",
    "    df.loc[ df[\"date_slot\"].str.contains(original_date),\n",
    "        [\"is_available\", \"patient_to_attend\"]\n",
    "    ] = [True, \"\"]\n",
    "\n",
    "    # Update the new time slot to be unavailable (False) and assign the patient to attend\n",
    "    df.loc[df[\"date_slot\"].str.contains(desired_date_time),\n",
    "        [\"is_available\", \"patient_to_attend\"],\n",
    "    ] = [False, patient_id]\n",
    "\n",
    "    # Write the updated DataFrame back to the CSV file\n",
    "    df.to_csv(availability_csv_path, index=False)\n",
    "\n",
    "    return \"Doctor's availability updated successfully.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_available = [check_availability_by_specialization, check_availability_by_doctor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "def create_agent(llm, tools, system_message: str):\n",
    "    \"\"\"Create an agent.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "                \" Use the provided tools to progress towards answering the question.\"\n",
    "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "                \" will help where you left off. Execute what you can to make progress.\"\n",
    "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    return prompt | llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=name)]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervisor agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "members = [\"Appointments\", \"Rag\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Analyze the user query well and then choose members. You do not need to go to all the members for a query When finished,\"\n",
    "    \" respond with FINISH. Only invoke one worker at once.\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[\"Appointments\", \"Rag\", \"FINISH\"]\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "\n",
    "def supervisor_agent_make(state):\n",
    "    supervisor_chain = prompt | llm.with_structured_output(routeResponse)\n",
    "    return supervisor_chain.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tools.tools_init_ import GetCustomTools\n",
    "\n",
    "toolsInstance = GetCustomTools()\n",
    "tools_available = toolsInstance.get_tools()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprebuilt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_react_agent\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# The agent state is the input to each node in the graph\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m Appointments \u001b[38;5;241m=\u001b[39m create_react_agent(\u001b[43mllm\u001b[49m, tools\u001b[38;5;241m=\u001b[39m[check_availability_by_doctor, check_availability_by_specialization,book_appointment, reschedule ], )\n\u001b[1;32m     17\u001b[0m                                 \u001b[38;5;66;03m#   inter=)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Appointments = create_agent(llm=llm,tools=[check_availability_by_doctor, check_availability_by_specialization,book_appointment, reschedule ],     system_message=\"You are an agent who is responsible for checking the availability of doctor based on doctor's name or specialization , booking appointments or rescheduling appointments of patients.\",\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Rag = create_agent(llm=llm,tools=[rag_gym],system_message=\"You are an agent who is responsible for answering questions related to TATA Punch Ev.\",)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m Rag \u001b[38;5;241m=\u001b[39m create_react_agent(llm, tools\u001b[38;5;241m=\u001b[39m[rag_gym])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "# import functools\n",
    "# import operator\n",
    "# from typing import Sequence\n",
    "# from typing_extensions import TypedDict\n",
    "\n",
    "# from langchain_core.messages import BaseMessage\n",
    "\n",
    "# from langgraph.graph import END, StateGraph, START\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "# # The agent state is the input to each node in the graph\n",
    "\n",
    "\n",
    "\n",
    "# Appointments = create_react_agent(llm, tools=[check_availability_by_doctor, check_availability_by_specialization,book_appointment, reschedule ], )\n",
    "#                                 #   inter=)\n",
    "# # Appointments = create_agent(llm=llm,tools=[check_availability_by_doctor, check_availability_by_specialization,book_appointment, reschedule ],     system_message=\"You are an agent who is responsible for checking the availability of doctor based on doctor's name or specialization , booking appointments or rescheduling appointments of patients.\",\n",
    "# # Rag = create_agent(llm=llm,tools=[rag_gym],system_message=\"You are an agent who is responsible for answering questions related to TATA Punch Ev.\",)\n",
    "# Rag = create_react_agent(llm, tools=[rag_gym])\n",
    "# Appointments_node = functools.partial(agent_node, agent=Appointments, name=\"Appointments\")\n",
    "# Rag_node = functools.partial(agent_node, agent=Rag, name=\"Rag\")\n",
    "\n",
    "# # # NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "# # code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
    "# # code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "# class AgentState(TypedDict):\n",
    "#     # The annotation tells the graph that new messages will always\n",
    "#     # be added to the current states\n",
    "#     messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "#     # The 'next' field indicates where to route to next\n",
    "#     next: str\n",
    "\n",
    "# workflow = StateGraph(AgentState)\n",
    "# workflow.add_node(\"Appointments\", Appointments_node)\n",
    "# workflow.add_node(\"Rag\", Rag_node)\n",
    "# workflow.add_node(\"supervisor_agent\", supervisor_agent_make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n",
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n",
      "Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Branch with name `None` already exists for node `supervisor_agent`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m conditional_map \u001b[38;5;241m=\u001b[39m {k: k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m members}\n\u001b[1;32m     12\u001b[0m conditional_map[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFINISH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m END\n\u001b[0;32m---> 13\u001b[0m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_conditional_edges\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msupervisor_agent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditional_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Finally, add entrypoint\u001b[39;00m\n\u001b[1;32m     16\u001b[0m workflow\u001b[38;5;241m.\u001b[39madd_edge(START, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupervisor_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Volumes/Ajeet/LLM Projects/LangGraph(KeepMe)/langGEnv/lib/python3.11/site-packages/langgraph/graph/graph.py:293\u001b[0m, in \u001b[0;36mGraph.add_conditional_edges\u001b[0;34m(self, source, path, path_map, then)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;66;03m# validate the condition\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranches[source]:\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBranch with name `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` already exists for node \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m     )\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# save it\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbranches[source][name] \u001b[38;5;241m=\u001b[39m Branch(path, path_map_, then)\n",
      "\u001b[0;31mValueError\u001b[0m: Branch with name `None` already exists for node `supervisor_agent`"
     ]
    }
   ],
   "source": [
    "# for member in members:\n",
    "#     # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "#     workflow.add_edge(member, \"supervisor_agent\")\n",
    "workflow.add_edge(\"Appointments\", \"supervisor_agent\")\n",
    "workflow.add_edge(\"Rag\", \"supervisor_agent\")\n",
    "\n",
    "\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "conditional_map = {k: k for k in members}\n",
    "\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor_agent\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "# Finally, add entrypoint\n",
    "workflow.add_edge(START, \"supervisor_agent\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Appointments': 'Appointments', 'Rag': 'Rag', 'FINISH': '__end__'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from Agent.agent_take2 import *\n",
    "from Libs.libs import *\n",
    "# from graph import  graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor_agent': {'next': 'Appointments'}}\n",
      "----\n",
      "\n",
      "from check availability by doctor tool\n",
      "desired date is: 2024-09-03\n",
      "\n",
      "---->>>>>>>              date_slot specialization     doctor_name  is_available  \\\n",
      "4262  2024-09-03 08:00   orthodontist  kevin anderson          True   \n",
      "4263  2024-09-03 08:30   orthodontist  kevin anderson          True   \n",
      "4269  2024-09-03 11:30   orthodontist  kevin anderson          True   \n",
      "4270  2024-09-03 12:00   orthodontist  kevin anderson          True   \n",
      "4271  2024-09-03 12:30   orthodontist  kevin anderson          True   \n",
      "4272  2024-09-03 13:00   orthodontist  kevin anderson          True   \n",
      "4274  2024-09-03 14:00   orthodontist  kevin anderson          True   \n",
      "4275  2024-09-03 14:30   orthodontist  kevin anderson          True   \n",
      "4276  2024-09-03 15:00   orthodontist  kevin anderson          True   \n",
      "4277  2024-09-03 15:30   orthodontist  kevin anderson          True   \n",
      "4279  2024-09-03 16:30   orthodontist  kevin anderson          True   \n",
      "\n",
      "     patient_to_attend  \n",
      "4262               NaN  \n",
      "4263               NaN  \n",
      "4269               NaN  \n",
      "4270               NaN  \n",
      "4271               NaN  \n",
      "4272               NaN  \n",
      "4274               NaN  \n",
      "4275               NaN  \n",
      "4276               NaN  \n",
      "4277               NaN  \n",
      "4279               NaN   >>>----- kevin anderson for 2024-09-03,\n",
      "Tool entered with the query kevin anderson for 2024-09-03,\n",
      "------------\n",
      "Hello! I see that you're looking to schedule an appointment with Dr. Kevin Anderson on September 3rd, 2024. I'm happy to inform you that he is available throughout the day with several time slots open. Here are the available times:\n",
      "\n",
      "- 08:00 AM\n",
      "- 08:30 AM\n",
      "- 11:30 AM\n",
      "- 12:00 PM\n",
      "- 12:30 PM\n",
      "- 01:00 PM\n",
      "- 02:00 PM\n",
      "- 02:30 PM\n",
      "- 03:00 PM\n",
      "- 03:30 PM\n",
      "- 04:30 PM\n",
      "\n",
      "Please let me know which time works best for you, and I'll get that scheduled!\n",
      "------------\n",
      "book tool activated 2024-09-03   08:00 AM\n",
      "desired date is: 2024-09-03T08:00 AM\n",
      "08:00 AM\n",
      "{'Appointments': {'messages': [HumanMessage(content='The 8:00 AM time slot is unfortunately not available for Dr. Kevin Anderson. However, here are the other available times on September 3rd, 2024:\\n\\n- 08:30 AM\\n- 11:30 AM\\n- 12:00 PM\\n- 12:30 PM\\n- 01:00 PM\\n- 02:00 PM\\n- 02:30 PM\\n- 03:00 PM\\n- 03:30 PM\\n- 04:30 PM\\n\\nPlease let me know which time works best for you!', additional_kwargs={}, response_metadata={}, name='Appointments')]}}\n",
      "----\n",
      "{'supervisor_agent': {'next': 'Rag'}}\n",
      "----\n",
      "{'Rag': {'messages': [HumanMessage(content='Please let me know which of the following available time slots for Dr. Kevin Anderson on September 3rd, 2024, works best for you:\\n\\n- 08:30 AM\\n- 11:30 AM\\n- 12:00 PM\\n- 12:30 PM\\n- 01:00 PM\\n- 02:00 PM\\n- 02:30 PM\\n- 03:00 PM\\n- 03:30 PM\\n- 04:30 PM', additional_kwargs={}, response_metadata={}, name='Rag')]}}\n",
      "----\n",
      "{'supervisor_agent': {'next': 'Rag'}}\n",
      "----\n",
      "{'Rag': {'messages': [HumanMessage(content='Please let me know which of the following available time slots for Dr. Kevin Anderson on September 3rd, 2024, works best for you:\\n\\n- 08:30 AM\\n- 11:30 AM\\n- 12:00 PM\\n- 12:30 PM\\n- 01:00 PM\\n- 02:00 PM\\n- 02:30 PM\\n- 03:00 PM\\n- 03:30 PM\\n- 04:30 PM', additional_kwargs={}, response_metadata={}, name='Rag')]}}\n",
      "----\n",
      "{'supervisor_agent': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "query = \"Book an appointment with  doctor kevin anderson available on september 3 2024 at 8 aM\"\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=query)\n",
    "        ]\n",
    "    },\n",
    "        {\"recursion_limit\": 100}\n",
    "\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from Libs.libs import *\n",
    "\n",
    "\n",
    "from Tools.availability_by_doctor import *\n",
    "from Tools.availability_by_specialization import *\n",
    "from Tools.booking import book_appointment\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], operator.add]\n",
    "    senderId:str\n",
    "    history:str\n",
    "    \n",
    "    \n",
    "tools_available = [book_appointment,check_availability_by_doctor, check_availability_by_specialization]\n",
    "# tool = [mercedes_tool]\n",
    "tool_node = ToolNode(tools=tools_available)\n",
    "model = llm.bind_tools(tools = tools_available, strict=True)\n",
    "\n",
    "def read_human_feedback(state):\n",
    "    # if state['messages'][-1].tool_calls == []:\n",
    "    #     logger.info(\"AI: \"+ state['messages'][-1].content)\n",
    "    #     user_msg = input(\"Reply: \")\n",
    "    \n",
    "    \n",
    "    # history = {\"history\":[]}\n",
    "    # history = getData(\"abcsdd\")\n",
    "    # if history is None:\n",
    "    #     history = {'history':[]}\n",
    "    # history_new = {\"human_feedback\":f\"{state['messages'][0].content}\", \"ai\":f\"{state['messages'][-1].content}\"}\n",
    "\n",
    "\n",
    "\n",
    "    # history = history_new.append(history['history'])\n",
    "    # history['history'].append(history_new)\n",
    "    # print(history)\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    # history['history'].append(history_new)\n",
    "    \n",
    "    # setData(state['senderId'], history)\n",
    "    \n",
    "    # if len(history['history'])>4:\n",
    "    #     length = len(history['history']) - 4\n",
    "    #     for i in range(length):\n",
    "    #         history[\"history\"].pop(0)\n",
    "    \n",
    "    # a = getData(\"abcsdd\")\n",
    "    # combined_history.append(a)\n",
    "    # {\"history\":combined_history}\n",
    "        \n",
    "    \n",
    "    \n",
    "    # print()\n",
    "    # print(state)\n",
    "    # print(\"history\",history)\n",
    "    # print()\n",
    "    return state\n",
    "    #     pass\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"From call_model the state is:\",state['senderId'])\n",
    "    s = getData(state[\"senderId\"])\n",
    "    state[\"history\"] = s\n",
    "    \n",
    "\n",
    "    # history = {\"human_feedback\":state[\"messages\"][1], \"AI\":\"This is ai response\"}\n",
    "    messages = [SystemMessage(content=f\"You are helpful assistant.\\n.As reference, today is {datetime.now().strftime('%Y-%m-%d %H:%M, %A')}\\nKeep a friendly, professional tone.\\nAvoid verbosity.\\nConsiderations:\\n- Don´t assume parameters in call functions that it didnt say.\\n- MUST NOT force users how to write. Let them write in the way they want.\\n- The conversation should be very natural like a secretary talking with a client.\\n- Call only ONE tool at a time.\")] + state['messages']\n",
    "    # messages = [SystemMessage(content=\"You are a helpful assistant. As reference, today is {datetime.now().strftime('%Y-%m-%d %H:%M, %A')}. Always use tools to answer the queries\")]\n",
    "\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"human_feedback\"]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"human_feedback\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def should_continue_with_feedback(state: MessagesState) -> Literal[\"agent\", \"FINISH\", \"human_feedback\"]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    if isinstance(last_message, dict):\n",
    "        if last_message.get(\"type\",\"\") == 'human_feedback':\n",
    "            return \"agent\"\n",
    "    if (isinstance(last_message, HumanMessage)):\n",
    "        return \"agent\"\n",
    "    if (isinstance(last_message, AIMessage)):\n",
    "        return \"FINISH\"\n",
    "    return \"FINISH\"\n",
    "\n",
    "\n",
    "\n",
    "def graph(query:str, senderId:str):\n",
    "    workflow = StateGraph(MessagesState)\n",
    "    workflow.add_node(\"agent\",call_model)\n",
    "    workflow.add_node(\"tools\",tool_node)\n",
    "    workflow.add_node(\"human_feedback\", read_human_feedback)\n",
    "\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\"human_feedback\":\"human_feedback\",\n",
    "        \"tools\":\"tools\"}\n",
    "    )\n",
    "    workflow.add_conditional_edges(\n",
    "        \"human_feedback\",\n",
    "        should_continue_with_feedback,\n",
    "        {\"agent\":\"agent\",\"FINISH\":END}\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(\"tools\",\"agent\" )\n",
    "\n",
    "\n",
    "    workflow.set_entry_point('agent')\n",
    "\n",
    "\n",
    "\n",
    "    graph = workflow.compile()\n",
    "    inputs = {\"messages\":[HumanMessage(content=query)], \"senderId\":senderId}\n",
    "\n",
    "    for response in graph.stream(inputs):\n",
    "        try:\n",
    "            if \"__end__\" not in response:\n",
    "                print(response)\n",
    "                # if 'human_feedback' in response:\n",
    "                token_usage =response['human_feedback']['messages'][-1].response_metadata['token_usage']\n",
    "                final_response =  response['human_feedback']['messages'][-1].content\n",
    "                    \n",
    "                print(\"-----\")\n",
    "                # history = {\"human_feedback\":query, \"ai\":final_response}\n",
    "                return {\"result\": final_response, \"token_usage\":token_usage}\n",
    "        except Exception as e:\n",
    "            print(\"error\", e)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tools.tools_init_ import *\n",
    "from Libs.libs import *\n",
    "\n",
    "from Libs.libs import llm\n",
    "from Libs.libs import llm\n",
    "\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from Redis.utilis import RedisSaver\n",
    "from Agent.supervisor_agent import agent_node, supervisor_agent_make\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from Libs.libs import *\n",
    "from Tools.tools_init_ import GetCustomTools\n",
    "from Tools.availability_by_doctor import check_availability_by_doctor\n",
    "from Tools.availability_by_specialization import check_availability_by_specialization\n",
    "from Tools.booking import book_appointment\n",
    "from Tools.reschedule import reschedule\n",
    "from Tools.ragAgent import rag_tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'should_continue_with_feedback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 108\u001b[0m\n\u001b[1;32m     91\u001b[0m workflow\u001b[38;5;241m.\u001b[39madd_conditional_edges(\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupervisor_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     93\u001b[0m should_continue,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m             }\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# workflow.add_conditional_edges(\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m#     \"human_feedback\",\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m#     should_continue_with_feedback,\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#     {\"supervisor_agent\":\"supervisor_agent\",\"FINISH\":END}\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    106\u001b[0m workflow\u001b[38;5;241m.\u001b[39madd_conditional_edges(\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAppointments\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 108\u001b[0m     \u001b[43mshould_continue_with_feedback\u001b[49m,\n\u001b[1;32m    109\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupervisor_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupervisor_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    114\u001b[0m workflow\u001b[38;5;241m.\u001b[39madd_conditional_edges(\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRag\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m     should_continue_with_feedback,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 }\n\u001b[1;32m    120\u001b[0m )\n\u001b[1;32m    124\u001b[0m workflow\u001b[38;5;241m.\u001b[39madd_edge(START, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupervisor_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'should_continue_with_feedback' is not defined"
     ]
    }
   ],
   "source": [
    "from Tools.tools_init_ import *\n",
    "from Libs.libs import *\n",
    "\n",
    "from Libs.libs import llm\n",
    "from Libs.libs import llm\n",
    "\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "from typing import Sequence, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from Redis.utilis import RedisSaver\n",
    "from Agent.supervisor_agent import agent_node, supervisor_agent_make\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from Libs.libs import *\n",
    "from Tools.tools_init_ import GetCustomTools\n",
    "from Tools.availability_by_doctor import check_availability_by_doctor\n",
    "from Tools.availability_by_specialization import check_availability_by_specialization\n",
    "from Tools.booking import book_appointment\n",
    "from Tools.reschedule import reschedule\n",
    "from Tools.ragAgent import rag_tool, create_custom_agent\n",
    "\n",
    "query = \"book an appointment with doctor kevin anderson for october 3 2024 16:00?\"\n",
    "\n",
    "\n",
    "\n",
    "def read_human_feedback(state):\n",
    "    return state\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "        \n",
    "def should_continue(state: MessagesState) -> Literal[\"Rag\",\"Appointments\"]:\n",
    "    print(\"Inside should continue\", state['next'])\n",
    "    # if state['next'] == \"FINISH\":\n",
    "        # return \"human_feedback\"\n",
    "    return state['next']\n",
    "    # messages = state['messages']\n",
    "    # print(\"message\",messages)\n",
    "    # last_message = messages[-1]\n",
    "    # print(\"from should continue\",last_message)\n",
    "    # if isinstance(last_message,routeResponse):\n",
    "    #     return f\"{last_message.next}\"\n",
    "    # return last_message\n",
    "\n",
    "# def should_continue_with_feedback(state: MessagesState) -> Literal['supervisor_agent', \"FINISH\", \"human_feedback\"]:\n",
    "    # messages = state['messages']\n",
    "    # last_message = messages[-1]\n",
    "    # if isinstance(last_message, dict):\n",
    "    #     if last_message.get(\"type\",\"\") == 'human_feedback':\n",
    "    #         return \"supervisor_agent\"\n",
    "    # if (isinstance(last_message, HumanMessage)):\n",
    "    #     return \"supervisor_agent\"\n",
    "    # if (isinstance(last_message, AIMessage)):\n",
    "    #     return \"FINISH\"\n",
    "    # return \"FINISH\"\n",
    "       \n",
    "        \n",
    "toolsInstance = GetCustomTools()\n",
    "tools_available = toolsInstance.get_tools()\n",
    "\n",
    "class routeResponse(BaseModel):\n",
    "    next: Literal[\"Appointments\", \"Rag\", \"FINISH\"]\n",
    "\n",
    "from Tools.ragAgent import create_custom_agent\n",
    "Appointments_agnet = create_custom_agent(prompt=\"\"\"You are an intelligent agent that answers queries related to the appointment with doctor based on doctor name, specialization, schedule appointment and reschedule appoinments.\"\"\", tools=tools_available, )\n",
    "Appointments_node = functools.partial(agent_node, agent=Appointments_agnet, name=\"Appointments\")\n",
    "\n",
    "Rag_agent = create_custom_agent(prompt=\"\"\"You are an intelligent agent that answers queries related to TATA Punch EV vehicles and its variants.\"\"\", tools=[rag_tool] )\n",
    "\n",
    "Rag_node = functools.partial(agent_node, agent=Rag_agent, name=\"Rag\")\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Appointments\", Appointments_node)\n",
    "workflow.add_node(\"Rag\", Rag_node)\n",
    "workflow.add_node(\"supervisor_agent\", supervisor_agent_make)\n",
    "# workflow.add_node(\"human_feedback\", read_human_feedback)\n",
    "\n",
    "# workflow.add_edge(\"Appointments\", \"supervisor_agent\")\n",
    "conditional_map = {'Appointments': 'Appointments', 'Rag': 'Rag', 'FINISH': '__end__'}\n",
    "# workflow.add_conditional_edges(\"supervisor_agent\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "\"supervisor_agent\",\n",
    "should_continue,\n",
    "        {\n",
    "            \"Rag\":\"Rag\",\n",
    "            \"Appointments\":\"Appointments\",\n",
    "            \"FINISH\":END\n",
    "            }\n",
    "    )\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"human_feedback\",\n",
    "#     should_continue_with_feedback,\n",
    "#     {\"supervisor_agent\":\"supervisor_agent\",\"FINISH\":END}\n",
    "# )\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"Appointments\",\n",
    "    should_continue_with_feedback,\n",
    "    {\"supervisor_agent\":\"supervisor_agent\"}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"Rag\",\n",
    "    should_continue_with_feedback,\n",
    "    {\n",
    "        \"supervisor_agent\":\"supervisor_agent\",\n",
    "                }\n",
    ")\n",
    "        \n",
    "        \n",
    "        \n",
    "workflow.add_edge(START, \"supervisor_agent\")\n",
    "graph = workflow.compile()\n",
    "\n",
    "\n",
    "\n",
    "        # from Agent.agent_take2 import *\n",
    "from Libs.libs import *\n",
    "# from graph import  graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "for s in graph.stream({\"messages\": [HumanMessage(content=query)]},{\"recursion_limit\": 100}):\n",
    "    if \"__end__\" not in s:\n",
    "        # if 'human_feedback' in s:\n",
    "            # print(s['human_feedback']['messages'])\n",
    "            # break\n",
    "        print(s)\n",
    "        print(\"----\")\n",
    "    else:\n",
    "        print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for s in graph.stream({\"messages\": [HumanMessage(content=query)]},{\"recursion_limit\": 100}):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")\n",
    "    else:\n",
    "        print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
